# Buildspec runs in the build stage of your pipeline.
version: 0.2
phases:
  install:
    runtime-versions:
      docker: 18
      ruby: 2.6
    commands:
      - echo "cd into $CODEBUILD_SRC_DIR"
      - cd $CODEBUILD_SRC_DIR
      # Download the copilot linux binary.
      - wget {{.BinaryS3BucketPath}}/copilot-linux-{{.Version}}
      - mv ./copilot-linux-{{.Version}} ./copilot-linux
      - chmod +x ./copilot-linux
  build:
    commands:
      - echo "Run your tests"
      # - make test
  post_build:
    commands:
      - ls -l
      - export COLOR="false"
      # First, upgrade the cloudformation stack of every environment in the pipeline.
      - pipeline=$(cat $CODEBUILD_SRC_DIR/copilot/pipeline.yml | ruby -ryaml -rjson -e 'puts JSON.pretty_generate(YAML.load(ARGF))')
      - pl_envs=$(echo $pipeline | jq '.stages[].name' | sed 's/"//g')
      - >
        for pl_env in $pl_envs; do
        ./copilot-linux env upgrade -n $pl_env;
        done;
      # Find all the local services in the workspace.
      - svcs=$(./copilot-linux svc ls --local --json | jq '.services[].name' | sed 's/"//g')
      # Find all the local jobs in the workspace.
      - jobs=$(./copilot-linux job ls --local --json | jq '.jobs[].name' | sed 's/"//g')
      # Find all the environments
      - envs=$(./copilot-linux env ls --json | jq '.environments[].name' | sed 's/"//g')
      # Generate the cloudformation templates.
      # The tag is the build ID but we replaced the colon ':' with a dash '-'.
      # We truncate the tag (from the front) to 128 characters, the limit for Docker tags
      # (https://docs.docker.com/engine/reference/commandline/tag/)
      - tag=$(sed 's/:/-/g' <<<"$CODEBUILD_BUILD_ID" | rev | cut -c 1-128 | rev)
      - >
        for env in $envs; do
          for svc in $svcs; do
          ./copilot-linux svc package -n $svc -e $env --output-dir './infrastructure' --tag $tag;
          done;
          for job in $jobs; do
          ./copilot-linux job package -n $job -e $env --output-dir './infrastructure' --tag $tag;
          done;
        done;
      - ls -lah ./infrastructure
      # Concatenate jobs and services into one var for addons
      # If addons exists, upload addons templates to each S3 bucket and write template URL to template config files.
      - WORKLOADS=$(echo $jobs $svcs)
      - |
        for workload in $WORKLOADS; do
          ADDONSFILE=./infrastructure/$workload.addons.stack.yml
          if [ -f "$ADDONSFILE" ]; then
            tmp=$(mktemp)
            timestamp=$(date +%s){{range $bucket := .ArtifactBuckets}}
            aws s3 cp "$ADDONSFILE" "s3://{{$bucket.BucketName}}/manual/$timestamp/$workload.addons.stack.yml";{{range $envName := $bucket.Environments}}
            jq --arg a "https://{{$bucket.BucketName}}.s3.{{$bucket.Region}}.amazonaws.com/manual/$timestamp/$workload.addons.stack.yml" '.Parameters.AddonsTemplateURL = $a' ./infrastructure/$workload-{{$envName}}.params.json > "$tmp" && mv "$tmp" ./infrastructure/$workload-{{$envName}}.params.json{{end}}{{end}}
          fi
        done;
      # Build images
      # - For each manifest file:
      #   - Read the path to the Dockerfile by translating the YAML file into JSON.
      #   - Run docker build.
      #   - For each environment:
      #     - Retrieve the ECR repository.
      #     - Login and push the image.
      - >
        for workload in $WORKLOADS; do
          manifest=$(cat $CODEBUILD_SRC_DIR/copilot/$workload/manifest.yml | ruby -ryaml -rjson -e 'puts JSON.pretty_generate(YAML.load(ARGF))')
          image_location=$(echo $manifest | jq '.image.location')
          if [ ! "$image_location" = null ]; then
            echo "skipping image building because location is provided as $image_location";
            continue
          fi
          base_dockerfile=$(echo $manifest | jq '.image.build')
          build_dockerfile=$(echo $manifest| jq 'if .image.build?.dockerfile? then .image.build.dockerfile else "" end' | sed 's/"//g')
          build_context=$(echo $manifest| jq 'if .image.build?.context? then .image.build.context else "" end' | sed 's/"//g')
          build_target=$(echo $manifest| jq 'if .image.build?.target? then .image.build.target else "" end' | sed 's/"//g')
          dockerfile_args=$(echo $manifest | jq 'if .image.build?.args? then .image.build.args else "" end | to_entries?')
          build_cache_from=$(echo $manifest | jq 'if .image.build?.cache_from? then .image.build.cache_from else "" end')
          df_rel_path=$( echo $base_dockerfile | sed 's/"//g')
          if [ -n "$build_dockerfile" ]; then 
            df_rel_path=$build_dockerfile
          fi
          df_path=$df_rel_path
          df_dir_path=$(dirname "$df_path")
          if [ -n "$build_context" ]; then
            df_dir_path=$build_context
          fi
          build_args=
          if [ -n "$dockerfile_args" ]; then
            for arg in $(echo $dockerfile_args | jq -r '.[] | "\(.key)=\(.value)"'); do 
              build_args="$build_args--build-arg $arg "
            done
          fi
          if [ -n "$build_target" ]; then
            build_args="$build_args--target $build_target "
          fi
          if [ -n "$build_cache_from" ]; then
            for arg in $(echo $build_cache_from | jq -r '.[]'); do
              build_args="$build_args--cache-from $arg "
            done
          fi
          echo "Name: $workload"
          echo "Relative Dockerfile path: $df_rel_path"
          echo "Docker build context: $df_dir_path"
          echo "Docker build args: $build_args"
          echo "Running command: docker build -t $workload:$tag $build_args-f $df_path $df_dir_path";
          docker build -t $workload:$tag $build_args-f $df_path $df_dir_path;
          image_id=$(docker images -q $workload:$tag);
          for env in $envs; do
            repo=$(cat $CODEBUILD_SRC_DIR/infrastructure/$workload-$env.params.json | jq '.Parameters.ContainerImage' | sed 's/"//g');
            region=$(echo $repo | cut -d'.' -f4);
            $(aws ecr get-login-password --region $region | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$region.amazonaws.com);
            docker tag $image_id $repo;
            docker push $repo;
          done;
        done;
artifacts:
  files:
    - "infrastructure/*"
